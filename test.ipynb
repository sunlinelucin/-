{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b15ef22bca27d0f3",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 文本分类"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7847658eb6283392",
   "metadata": {
    "collapsed": false
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "47caaaff7c5fa375",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 导入包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "101e7092",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T16:27:56.626394Z",
     "start_time": "2025-06-15T16:27:56.595131800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "\n",
    "import os\n",
    "os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f9a6dbe6c08f3",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 设置日志"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e852990a1755c1e3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T16:27:58.611688100Z",
     "start_time": "2025-06-15T16:27:58.513966600Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e487b4e4e7c6d8e",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 设置随机种子以确保可重复性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "745ec0285381bbb2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T16:28:00.238458100Z",
     "start_time": "2025-06-15T16:28:00.167405300Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13e897cf0bda2ff",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 检查设备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e15ccd7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T16:28:02.033374300Z",
     "start_time": "2025-06-15T16:28:02.001070900Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:使用设备: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "logger.info(f\"使用设备: {device}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4773663bbfd51580",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 数据集类定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7f726d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T12:17:45.631934Z",
     "start_time": "2025-06-15T12:17:45.622172900Z"
    }
   },
   "outputs": [],
   "source": [
    "class TextClassificationDataset(Dataset):\n",
    "    \"\"\"\n",
    "    自定义数据集类，用于加载和预处理文本分类任务的数据\n",
    "    继承自PyTorch的Dataset类\n",
    "    \"\"\"\n",
    "    def __init__(self, file_path, tokenizer, max_length=512):\n",
    "        \"\"\"\n",
    "        初始化数据集\n",
    "        \n",
    "        参数:\n",
    "            file_path: 数据文件路径，文件应为jsonl格式\n",
    "            tokenizer: BERT分词器，用于将文本转换为模型输入\n",
    "            max_length: 文本最大长度，默认为512个token\n",
    "        \"\"\"\n",
    "        self.texts = []  # 存储文本数据\n",
    "        self.labels = []  # 存储标签数据\n",
    "        self.tokenizer = tokenizer  # BERT分词器\n",
    "        self.max_length = max_length  # 最大序列长度\n",
    "        \n",
    "        # 读取jsonl格式文件\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                data = json.loads(line.strip())\n",
    "                self.texts.append(data['text'])  # 提取文本\n",
    "                if 'label' in data:  # 只有训练数据有标签\n",
    "                    self.labels.append(data['label'])  # 提取标签\n",
    "                    \n",
    "        # 对于测试数据（无标签），用-1填充标签列表\n",
    "        if not self.labels:  # 对于测试数据\n",
    "            self.labels = [-1] * len(self.texts)\n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\"返回数据集中样本数量\"\"\"\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        获取指定索引的样本\n",
    "        \n",
    "        参数:\n",
    "            idx: 样本索引\n",
    "            \n",
    "        返回:\n",
    "            包含模型输入所需的所有张量的字典\n",
    "        \"\"\"\n",
    "        text = self.texts[idx]  # 获取文本\n",
    "        label = self.labels[idx]  # 获取标签\n",
    "        \n",
    "        # 使用BERT分词器处理文本\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            max_length=self.max_length,  # 截断/填充到指定长度\n",
    "            padding='max_length',  # 填充到最大长度\n",
    "            truncation=True,  # 截断超长文本\n",
    "            return_tensors='pt'  # 返回PyTorch张量\n",
    "        )\n",
    "        \n",
    "        # 返回模型需要的所有输入\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].squeeze(),  # 移除批次维度\n",
    "            'attention_mask': encoding['attention_mask'].squeeze(),  # 移除批次维度\n",
    "            'label': torch.tensor(label, dtype=torch.long)  # 转换为LongTensor类型\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1de9c045d389dd4",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 模型定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3213ec4c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T12:17:48.004024500Z",
     "start_time": "2025-06-15T12:17:47.973638400Z"
    }
   },
   "outputs": [],
   "source": [
    "class TextClassifier(nn.Module):\n",
    "    def __init__(self, bert_model, dropout_rate=0.3):\n",
    "        super(TextClassifier, self).__init__()\n",
    "        self.bert = bert_model\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.classifier = nn.Linear(bert_model.config.hidden_size, 2)\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs.pooler_output\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.classifier(pooled_output)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221b721423309e4b",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 训练函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65adcc93",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T12:17:50.175562Z",
     "start_time": "2025-06-15T12:17:50.148980300Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, optimizer, criterion, device):\n",
    "    \"\"\"训练模型的函数，执行一个完整训练周期\"\"\"\n",
    "    model.train()  # 设置模型为训练模式\n",
    "    total_loss = 0\n",
    "    predictions = []  # 存储所有预测结果\n",
    "    true_labels = []  # 存储所有真实标签\n",
    "    \n",
    "    # 创建进度条，方便观察训练进度\n",
    "    progress_bar = tqdm(train_loader, desc=\"训练中\", ncols=100)\n",
    "    batch_count = 0\n",
    "    running_loss = 0  # 用于计算移动平均损失\n",
    "    \n",
    "    for batch in progress_bar:\n",
    "        # 将数据移至指定设备(CPU/GPU)\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()  # 清除之前的梯度\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)  # 前向传播\n",
    "        loss = criterion(outputs, labels)  # 计算损失\n",
    "        \n",
    "        loss.backward()  # 反向传播计算梯度\n",
    "        optimizer.step()  # 更新模型参数\n",
    "        \n",
    "        # 更新损失统计和进度条显示\n",
    "        batch_count += 1\n",
    "        running_loss = (running_loss * (batch_count - 1) + loss.item()) / batch_count\n",
    "        progress_bar.set_postfix({\n",
    "            '当前损失': f'{loss.item():.4f}',\n",
    "            '平均损失': f'{running_loss:.4f}'\n",
    "        })\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        # 收集预测结果和真实标签用于计算F1分数\n",
    "        predictions.extend(outputs.argmax(dim=1).cpu().numpy())\n",
    "        true_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        # 清理内存，减少内存占用\n",
    "        del input_ids, attention_mask, labels, outputs, loss\n",
    "        if batch_count % 10 == 0:  # 定期执行垃圾回收\n",
    "            gc.collect()\n",
    "    \n",
    "    # 计算整个epoch的平均损失和F1分数\n",
    "    epoch_loss = total_loss / len(train_loader)\n",
    "    epoch_f1 = f1_score(true_labels, predictions)\n",
    "    \n",
    "    return epoch_loss, epoch_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c9ea5111ba06af",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 评估函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ab89cc3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T12:17:53.095111400Z",
     "start_time": "2025-06-15T12:17:53.072265300Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, eval_loader, criterion, device):\n",
    "    \"\"\"评估模型性能的函数，不进行梯度计算和参数更新\"\"\"\n",
    "    model.eval()  # 设置模型为评估模式\n",
    "    total_loss = 0\n",
    "    predictions = []  # 存储预测结果\n",
    "    true_labels = []  # 存储真实标签\n",
    "    \n",
    "    progress_bar = tqdm(eval_loader, desc=\"评估中\", ncols=100)\n",
    "    \n",
    "    with torch.no_grad():  # 不计算梯度，减少内存使用\n",
    "        for batch in progress_bar:\n",
    "            # 将数据移至指定设备\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "            \n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)  # 前向传播\n",
    "            loss = criterion(outputs, labels)  # 计算损失\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            # 收集预测结果和真实标签\n",
    "            predictions.extend(outputs.argmax(dim=1).cpu().numpy())\n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "            \n",
    "            progress_bar.set_postfix({'当前损失': f'{loss.item():.4f}'})\n",
    "            \n",
    "            # 清理内存\n",
    "            del input_ids, attention_mask, labels, outputs, loss\n",
    "            gc.collect()\n",
    "    \n",
    "    # 计算整体评估指标\n",
    "    epoch_loss = total_loss / len(eval_loader)\n",
    "    epoch_f1 = f1_score(true_labels, predictions)  # 计算F1分数\n",
    "    \n",
    "    return epoch_loss, epoch_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397d8964f78db01a",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 预测函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "613100ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T12:17:55.374995400Z",
     "start_time": "2025-06-15T12:17:55.351917200Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict(model, test_loader, device):\n",
    "    \"\"\"预测函数，用于对测试数据进行推理并返回预测结果\"\"\"\n",
    "    model.eval()  # 设置模型为评估模式\n",
    "    predictions = []  # 存储所有预测结果\n",
    "    \n",
    "    progress_bar = tqdm(test_loader, desc=\"预测中\", ncols=100)\n",
    "    \n",
    "    with torch.no_grad():  # 不计算梯度，提高推理速度和减少内存使用\n",
    "        for batch in progress_bar:\n",
    "            # 将输入数据移至指定设备\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            \n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)  # 模型推理\n",
    "            predictions.extend(outputs.argmax(dim=1).cpu().numpy())  # 获取预测类别\n",
    "            \n",
    "            # 清理内存，避免内存泄漏\n",
    "            del input_ids, attention_mask, outputs\n",
    "            gc.collect()\n",
    "    \n",
    "    return predictions  # 返回所有预测结果列表"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396fedbd5bbe9f9a",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 模型训练与评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c4ed559",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T12:37:27.148957200Z",
     "start_time": "2025-06-15T12:37:15.888678800Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:开始加载预训练模型...\n"
     ]
    }
   ],
   "source": [
    "# 超参数\n",
    "BATCH_SIZE = 16  # CPU上可以使用更大的批次大小\n",
    "EPOCHS = 3\n",
    "LEARNING_RATE = 2e-5\n",
    "MAX_LENGTH = 512\n",
    "\n",
    "logger.info(\"开始加载预训练模型...\")\n",
    "# 初始化分词器和模型\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert_model = BertModel.from_pretrained('bert-base-uncased')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7566df253b8d7b2",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 准备数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f3883925d4e2a18d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T13:21:16.203796100Z",
     "start_time": "2025-06-15T13:21:16.033178900Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:准备数据集...\n",
      "INFO:__main__:训练集大小: 28000, 测试集大小: 2800\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"准备数据集...\")\n",
    "# 创建数据集\n",
    "train_dataset = TextClassificationDataset('train.jsonl', tokenizer, MAX_LENGTH)\n",
    "test_dataset = TextClassificationDataset('test.jsonl', tokenizer, MAX_LENGTH)\n",
    "\n",
    "logger.info(f\"训练集大小: {len(train_dataset)}, 测试集大小: {len(test_dataset)}\")\n",
    "\n",
    "# 创建数据加载器\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6330ef723b45e2",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 初始化模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "21d2bf12",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-06-15T12:37:39.026491800Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:初始化模型...\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"初始化模型...\")\n",
    "# 初始化模型、损失函数和优化器\n",
    "model = TextClassifier(bert_model).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4ca2e11f6afa11",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 训练循环"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b9488739f10d9f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T12:53:10.867995700Z",
     "start_time": "2025-06-15T12:37:45.176082700Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:\n",
      "第 1/3 轮训练\n",
      "训练中: 100%|███████████████████████| 4/4 [04:19<00:00, 64.86s/it, 当前损失=0.6018, 平均损失=0.6788], ?it/s]\n",
      "INFO:__main__:训练损失: 0.6788, 训练F1分数: 0.7368\n",
      "INFO:__main__:保存最佳模型 (F1: 0.7368)\n",
      "INFO:__main__:\n",
      "第 2/3 轮训练\n",
      "训练中: 100%|███████████████████████| 4/4 [05:19<00:00, 79.84s/it, 当前损失=0.6900, 平均损失=0.6095], ?it/s]\n",
      "INFO:__main__:训练损失: 0.6095, 训练F1分数: 0.8254\n",
      "INFO:__main__:保存最佳模型 (F1: 0.8254)\n",
      "INFO:__main__:\n",
      "第 3/3 轮训练\n",
      "训练中: 100%|███████████████████████| 4/4 [05:39<00:00, 84.82s/it, 当前损失=0.4180, 平均损失=0.4808], ?it/s]\n",
      "INFO:__main__:训练损失: 0.4808, 训练F1分数: 0.9062\n",
      "INFO:__main__:保存最佳模型 (F1: 0.9062)\n"
     ]
    }
   ],
   "source": [
    "best_f1 = 0\n",
    "for epoch in range(EPOCHS):\n",
    "    logger.info(f\"\\n第 {epoch+1}/{EPOCHS} 轮训练\")\n",
    "    \n",
    "    train_loss, train_f1 = train_model(model, train_loader, optimizer, criterion, device)\n",
    "    logger.info(f\"训练损失: {train_loss:.4f}, 训练F1分数: {train_f1:.4f}\")\n",
    "    \n",
    "    if train_f1 > best_f1:\n",
    "        best_f1 = train_f1\n",
    "        logger.info(f\"保存最佳模型 (F1: {best_f1:.4f})\")\n",
    "        torch.save(model.state_dict(), 'model.pt')\n",
    "    \n",
    "    # 进行垃圾回收\n",
    "    gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d09e97e0d262485",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 加载最佳模型并进行预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c253a5d6",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-06-15T12:53:16.638878900Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:\n",
      "开始预测...\n",
      "预测中: 100%|█████████████████████████████████████████████████████████| 4/4 [00:32<00:00,  8.19s/it]\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"\\n开始预测...\")\n",
    "model.load_state_dict(torch.load('model.pt'))\n",
    "predictions = predict(model, test_loader, device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5329926960130e84",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 保存预测结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T13:18:31.650080800Z",
     "start_time": "2025-06-15T13:18:31.617770600Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:保存预测结果...\n",
      "INFO:__main__:预测结果保存到 submit.txt\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"保存预测结果...\")\n",
    "with open('submit.txt', 'w') as f:\n",
    "    for pred in predictions:\n",
    "        f.write(f\"{pred}\\n\")\n",
    "\n",
    "logger.info(\"预测结果保存到 submit.txt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
